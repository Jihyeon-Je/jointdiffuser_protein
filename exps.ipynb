{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "import torch\n",
    "from torch import multiprocessing as mp\n",
    "from datasets import get_dataset\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import utils\n",
    "import einops\n",
    "#from torch.uatils._pytree import tree_map\n",
    "import accelerate\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from dpm_solver_pp import NoiseScheduleVP, DPM_Solver\n",
    "import tempfile\n",
    "from fid_score import calculate_fid_given_paths\n",
    "from absl import logging\n",
    "import builtins\n",
    "import os\n",
    "import wandb\n",
    "import libs.autoencoder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils._pytree import tree_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "\n",
    "def d(**kwargs):\n",
    "    \"\"\"Helper of creating a config dict.\"\"\"\n",
    "    return ml_collections.ConfigDict(initial_dictionary=kwargs)\n",
    "    \n",
    "config = ml_collections.ConfigDict()\n",
    "config.seed = 1234\n",
    "config.z_shape = (3, 1296, 4)\n",
    "config.config_name = 'test'\n",
    "config.ckpt_root = '/Users/jihyeonje/unidiffuser/test/'\n",
    "config.sample_dir = '/Users/jihyeonje/unidiffuser/test/'\n",
    "config.workdir = '/Users/jihyeonje/unidiffuser/test/'\n",
    "config.hparams = 'default'\n",
    "\n",
    "config.autoencoder = d(\n",
    "    pretrained_path='assets/stable-diffusion/autoencoder_kl.pth',\n",
    "    scale_factor=0.23010\n",
    ")\n",
    "config.train = d(\n",
    "    n_steps=50,\n",
    "    batch_size=2,\n",
    "    log_interval=10,\n",
    "    eval_interval=5,\n",
    "    save_interval=5\n",
    ")\n",
    "\n",
    "config.optimizer = d(\n",
    "    name='adamw',\n",
    "    lr=0.0002,\n",
    "    weight_decay=0.03,\n",
    "    betas=(0.9, 0.9)\n",
    ")\n",
    "\n",
    "config.lr_scheduler = d(\n",
    "    name='customized',\n",
    "    warmup_steps=5000\n",
    ")\n",
    "\n",
    "config.nnet = d(\n",
    "    name='uvit_t2i',\n",
    "    img_size=1296,\n",
    "    in_chans=3,\n",
    "    patch_size=4,\n",
    "    embed_dim=100,\n",
    "    depth=12,\n",
    "    num_heads=10,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=False,\n",
    "    mlp_time_embed=False,\n",
    "    clip_dim=19,\n",
    "    num_clip_token=77\n",
    ")\n",
    "\n",
    "config.dataset = d(\n",
    "    name='ligprot_features',\n",
    "    path='test/feats',\n",
    "    cfg=False,\n",
    "    p_uncond=0.1\n",
    ")\n",
    "\n",
    "config.sample = d(\n",
    "    sample_steps=2,\n",
    "    n_samples=5,\n",
    "    mini_batch_size=1,\n",
    "    cfg=False,\n",
    "    scale=1.,\n",
    "    path='/Users/jihyeonje/unidiffuser/test/res/'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_diffusion_beta_schedule(linear_start=0.00085, linear_end=0.0120, n_timestep=1000):\n",
    "    _betas = (torch.linspace(linear_start ** 0.5, linear_end ** 0.5, n_timestep, dtype=torch.float64) ** 2)\n",
    "    return _betas.numpy()\n",
    "\n",
    "\n",
    "def get_skip(alphas, betas):\n",
    "    N = len(betas) - 1\n",
    "    skip_alphas = np.ones([N + 1, N + 1], dtype=betas.dtype)\n",
    "    for s in range(N + 1):\n",
    "        skip_alphas[s, s + 1:] = alphas[s + 1:].cumprod()\n",
    "    skip_betas = np.zeros([N + 1, N + 1], dtype=betas.dtype)\n",
    "    for t in range(N + 1):\n",
    "        prod = betas[1: t + 1] * skip_alphas[1: t + 1, t]\n",
    "        skip_betas[:t, t] = (prod[::-1].cumsum())[::-1]\n",
    "    return skip_alphas, skip_betas\n",
    "\n",
    "\n",
    "def stp(s, ts: torch.Tensor):  # scalar tensor product\n",
    "    if isinstance(s, np.ndarray):\n",
    "        s = torch.from_numpy(s).type_as(ts)\n",
    "    extra_dims = (1,) * (ts.dim() - 1)\n",
    "    return s.view(-1, *extra_dims) * ts\n",
    "\n",
    "\n",
    "def mos(a, start_dim=1):  # mean of square\n",
    "    return a.pow(2).flatten(start_dim=start_dim).mean(dim=-1)\n",
    "\n",
    "def LSimple(x0, y0, nnet, schedule, **kwargs):\n",
    "    n, eps_x, eps_y, xn, yn = schedule.sample(x0, y0)  # n in {1, ..., 1000}\n",
    "    #n= timestep\n",
    "    eps_pred_prot, eps_pred_lig = nnet(xn, n, n, yn)\n",
    "\n",
    "    mos_p = mos(eps_x - eps_pred_prot)\n",
    "    mos_l = mos(eps_y - eps_pred_lig)\n",
    "    return mos_p + mos_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Schedule(object):  # discrete time\n",
    "    def __init__(self, _betas):\n",
    "        r\"\"\" _betas[0...999] = betas[1...1000]\n",
    "             for n>=1, betas[n] is the variance of q(xn|xn-1)\n",
    "             for n=0,  betas[0]=0\n",
    "        \"\"\"\n",
    "\n",
    "        self._betas = _betas\n",
    "        self.betas = np.append(0., _betas)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.N = len(_betas)\n",
    "\n",
    "        assert isinstance(self.betas, np.ndarray) and self.betas[0] == 0\n",
    "        assert isinstance(self.alphas, np.ndarray) and self.alphas[0] == 1\n",
    "        assert len(self.betas) == len(self.alphas)\n",
    "\n",
    "        # skip_alphas[s, t] = alphas[s + 1: t + 1].prod()\n",
    "        self.skip_alphas, self.skip_betas = get_skip(self.alphas, self.betas)\n",
    "        self.cum_alphas = self.skip_alphas[0]  # cum_alphas = alphas.cumprod()\n",
    "        self.cum_betas = self.skip_betas[0]\n",
    "        self.snr = self.cum_alphas / self.cum_betas\n",
    "\n",
    "    def tilde_beta(self, s, t):\n",
    "        return self.skip_betas[s, t] * self.cum_betas[s] / self.cum_betas[t]\n",
    "\n",
    "    def sample(self, x0, y0):  # \n",
    "        n = np.random.choice(list(range(1, self.N + 1)), (len(x0),))\n",
    "        eps_x = torch.randn_like(x0)\n",
    "        eps_y = torch.randn_like(y0)\n",
    "        xn = stp(self.cum_alphas[n] ** 0.5, x0) + stp(self.cum_betas[n] ** 0.5, eps_x)\n",
    "        yn = stp(self.cum_alphas[n] ** 0.5, y0) + stp(self.cum_betas[n] ** 0.5, eps_y)\n",
    "        return torch.tensor(n, device=x0.device), eps_x, eps_y, xn, yn\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Schedule({self.betas[:10]}..., {self.N})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_joint(z, text):\n",
    "    z = einops.rearrange(z, 'B C H W -> B (C H W)')\n",
    "    text = einops.rearrange(text, 'B L D -> B (L D)')\n",
    "    return torch.concat([z, text], dim=-1)\n",
    "\n",
    "def split_joint(x):\n",
    "    C, H, W = 3, 1296, 4\n",
    "    z_dim = C * H * W\n",
    "    z, text = x.split([z_dim, 100 * 19], dim=1)\n",
    "    z = einops.rearrange(z, 'B (C H W) -> B C H W', C=C, H=H, W=W)\n",
    "    text = einops.rearrange(text, 'B (L D) -> B L D', L=100, D=19)\n",
    "    return z, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "#    if config.get('benchmark', False):\n",
    "#        torch.backends.cudnn.benchmark = True\n",
    "#        torch.backends.cudnn.deterministic = False\n",
    "\n",
    "    #mp.set_start_method('spawn')\n",
    "    accelerator = accelerate.Accelerator()\n",
    "    device = accelerator.device\n",
    "    accelerate.utils.set_seed(config.seed, device_specific=True)\n",
    "    logging.info(f'Process {accelerator.process_index} using device: {device}')\n",
    "\n",
    "    config.mixed_precision = accelerator.mixed_precision\n",
    "    config = ml_collections.FrozenConfigDict(config)\n",
    "\n",
    "    assert config.train.batch_size % accelerator.num_processes == 0\n",
    "    mini_batch_size = config.train.batch_size // accelerator.num_processes\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        os.makedirs(config.ckpt_root, exist_ok=True)\n",
    "        os.makedirs(config.sample_dir, exist_ok=True)\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        wandb.init(dir=os.path.abspath(config.workdir), project=f'uvit_{config.dataset.name}', config=config.to_dict(),\n",
    "                   name=config.hparams, job_type='train', mode='offline')\n",
    "        utils.set_logger(log_level='info', fname=os.path.join(config.workdir, 'output.log'))\n",
    "        logging.info(config)\n",
    "    else:\n",
    "        utils.set_logger(log_level='error')\n",
    "        builtins.print = lambda *args: None\n",
    "    logging.info(f'Run on {accelerator.num_processes} devices')\n",
    "\n",
    "    dataset = get_dataset(**config.dataset)\n",
    "    #assert os.path.exists(dataset.fid_stat)\n",
    "    train_dataset = dataset.get_split(split='train', labeled=True)\n",
    "    train_dataset_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True, drop_last=True,\n",
    "                                      num_workers=1, pin_memory=True, persistent_workers=True)\n",
    "    test_dataset = dataset.get_split(split='test', labeled=True)  # for sampling\n",
    "    test_dataset_loader = DataLoader(test_dataset, batch_size=config.sample.mini_batch_size, shuffle=True, drop_last=True,\n",
    "                                     num_workers=1, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "    train_state = utils.initialize_train_state(config, device)\n",
    "    nnet, nnet_ema, optimizer, train_dataset_loader, test_dataset_loader = accelerator.prepare(\n",
    "        train_state.nnet, train_state.nnet_ema, train_state.optimizer, train_dataset_loader, test_dataset_loader)\n",
    "    lr_scheduler = train_state.lr_scheduler\n",
    "    train_state.resume(config.ckpt_root)\n",
    "\n",
    "\n",
    "    #autoencoder = libs.autoencoder.get_model(**config.autoencoder)\n",
    "    #autoencoder.to(device)\n",
    "\n",
    "    #@ torch.cuda.amp.autocast()\n",
    "    #def encode(_batch):\n",
    "    #    return autoencoder.encode(_batch)\n",
    "\n",
    "    #@ torch.cuda.amp.autocast()\n",
    "    #def decode(_batch):\n",
    "    #    return autoencoder.decode(_batch)\n",
    "\n",
    "    def get_data_generator():\n",
    "        while True:\n",
    "            for data in tqdm(train_dataset_loader, disable=not accelerator.is_main_process, desc='epoch'):\n",
    "                yield data\n",
    "\n",
    "    data_generator = get_data_generator()\n",
    "\n",
    "    def get_context_generator():\n",
    "        while True:\n",
    "            for data in test_dataset_loader:\n",
    "                yield data[0], data[1]\n",
    "\n",
    "    context_generator = get_context_generator()\n",
    "    \n",
    "    _betas = stable_diffusion_beta_schedule()\n",
    "    _schedule = Schedule(_betas)\n",
    "    logging.info(f'use {_schedule}')\n",
    "\n",
    "    def cfg_nnet(x, timesteps, context):\n",
    "        _cond = nnet_ema(x, timesteps, context=context)\n",
    "        _empty_context = torch.tensor(dataset.empty_context, device=device)\n",
    "        _empty_context = einops.repeat(_empty_context, 'L D -> B L D', B=x.size(0))\n",
    "        _uncond = nnet_ema(x, timesteps, context=_empty_context)\n",
    "        return _cond + config.sample.scale * (_cond - _uncond)\n",
    "\n",
    "    def joint_nnet(x, timesteps):\n",
    "        z, text = split_joint(x)\n",
    "        z_out, text_out = nnet(z, t_prot=timesteps, t_lig=timesteps, context = text)\n",
    "        if len(z_out.shape)==3:\n",
    "            z_out = torch.unsqueeze(z_out, 0)\n",
    "            text_out = torch.unsqueeze(text_out, 0)\n",
    "        x_out = combine_joint(z_out, text_out)\n",
    "\n",
    "        return x_out\n",
    "\n",
    "\n",
    "    def train_step(_batch):\n",
    "        _metrics = dict()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = LSimple(_batch[0], _batch[1], nnet, _schedule)  # currently only support the extracted feature version\n",
    "        _metrics['loss'] = accelerator.gather(loss.detach()).mean()\n",
    "        accelerator.backward(loss.mean())\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        train_state.ema_update(config.get('ema_rate', 0.9999))\n",
    "        train_state.step += 1\n",
    "        return dict(lr=train_state.optimizer.param_groups[0]['lr'], **_metrics)\n",
    "    \n",
    "\n",
    "    def sample_fn(_n_samples, sample_steps):\n",
    "        _z_init = torch.randn(_n_samples, *config.z_shape, device=device)\n",
    "        _t_init = torch.randn(_n_samples, *(100,19), device=device)\n",
    "        _x_init = combine_joint(_z_init, _t_init)\n",
    "        noise_schedule = NoiseScheduleVP(schedule='discrete', betas=torch.tensor(_betas, device=device).float())\n",
    "\n",
    "        def model_fn(x, t_continuous):\n",
    "            t = t_continuous * _schedule.N\n",
    "            return joint_nnet(_x_init, t)\n",
    "\n",
    "        dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True, thresholding=False)\n",
    "        _z = dpm_solver.sample(_x_init, steps=sample_steps, eps=1. / _schedule.N, T=1.)\n",
    "        prot, lig = split_joint(_z)\n",
    "        return prot, lig\n",
    "\n",
    "    \n",
    "    def eval_step(n_samples, sample_steps):\n",
    "        logging.info(f'eval_step: n_samples={n_samples}, sample_steps={sample_steps}, algorithm=dpm_solver, '\n",
    "                     f'mini_batch_size={config.sample.mini_batch_size}')\n",
    "\n",
    "        _z, _text = sample_fn(n_samples, sample_steps)\n",
    "        with tempfile.TemporaryDirectory() as temp_path:\n",
    "            path = config.sample.path or temp_path\n",
    "            if accelerator.is_main_process:\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "            utils.sample2dir(accelerator, path, n_samples, config.sample.mini_batch_size, sample_fn, sample_steps, dataset.unpreprocess)\n",
    "\n",
    "            score = 0\n",
    "            if accelerator.is_main_process:\n",
    "                score = calculate_fid_given_paths((path))\n",
    "                logging.info(f'step={train_state.step} eval{n_samples}={score}')\n",
    "                with open(os.path.join(config.workdir, 'eval.log'), 'a') as f:\n",
    "                    print(f'step={train_state.step} score{n_samples}={score}', file=f)\n",
    "                wandb.log({f'score{n_samples}': score}, step=train_state.step)\n",
    "            score = torch.tensor(score, device=device)\n",
    "            #_fid = accelerator.reduce(_fid, reduction='sum')\n",
    "\n",
    "        return score\n",
    "\n",
    "    logging.info(f'Start fitting, step={train_state.step}, mixed_precision={config.mixed_precision}')\n",
    "\n",
    "    step_score = []\n",
    "    while train_state.step < config.train.n_steps:\n",
    "        nnet.train()\n",
    "        batch = tree_map(lambda x: x.to(device), next(data_generator))\n",
    "        metrics = train_step(batch)\n",
    "\n",
    "        nnet.eval()\n",
    "        if accelerator.is_main_process and train_state.step % config.train.log_interval == 0:\n",
    "            logging.info(utils.dct2str(dict(step=train_state.step, **metrics)))\n",
    "            logging.info(config.workdir)\n",
    "            wandb.log(metrics, step=train_state.step)\n",
    "\n",
    "        if accelerator.is_main_process and train_state.step % config.train.eval_interval == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            #contexts = torch.tensor(dataset.contexts, device=device)[: 2 * 5]\n",
    "            #samples = dpm_solver_sample(_n_samples=2 * 5, _sample_steps=50, context=contexts)\n",
    "            #samples = make_grid(dataset.unpreprocess(samples), 5)\n",
    "            #save_image(samples, os.path.join(config.sample_dir, f'{train_state.step}.png'))\n",
    "            #wandb.log({'samples': wandb.Image(samples)}, step=train_state.step)\n",
    "            torch.cuda.empty_cache()\n",
    "        #accelerator.wait_for_everyone()\n",
    "\n",
    "        if train_state.step % config.train.save_interval == 0 or train_state.step == config.train.n_steps:\n",
    "            torch.cuda.empty_cache()\n",
    "            logging.info(f'Save and eval checkpoint {train_state.step}...')\n",
    "            if accelerator.local_process_index == 0:\n",
    "                train_state.save(os.path.join(config.ckpt_root, f'{train_state.step}.ckpt'))\n",
    "            accelerator.wait_for_everyone()\n",
    "            score = eval_step(n_samples=5, sample_steps=5)  # calculate fid of the saved checkpoint\n",
    "            step_score.append((train_state.step, score))\n",
    "            torch.cuda.empty_cache()\n",
    "        #accelerator.wait_for_everyone()\n",
    "\n",
    "    logging.info(f'Finish fitting, step={train_state.step}')\n",
    "    logging.info(f'step_score: {step_score}')\n",
    "    step_best = sorted(step_score, key=lambda x: x[1])[0][0]\n",
    "    logging.info(f'step_best: {step_best}')\n",
    "    train_state.load(os.path.join(config.ckpt_root, f'{step_best}.ckpt'))\n",
    "    del metrics\n",
    "    #accelerator.wait_for_everyone()\n",
    "    eval_step(n_samples=config.sample.n_samples, sample_steps=config.sample.sample_steps)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:autoencoder:\n",
      "  pretrained_path: assets/stable-diffusion/autoencoder_kl.pth\n",
      "  scale_factor: 0.2301\n",
      "ckpt_root: /Users/jihyeonje/unidiffuser/test/\n",
      "config_name: test\n",
      "dataset:\n",
      "  cfg: false\n",
      "  name: ligprot_features\n",
      "  p_uncond: 0.1\n",
      "  path: test/feats\n",
      "hparams: default\n",
      "lr_scheduler:\n",
      "  name: customized\n",
      "  warmup_steps: 5000\n",
      "mixed_precision: 'no'\n",
      "nnet:\n",
      "  clip_dim: 19\n",
      "  depth: 12\n",
      "  embed_dim: 100\n",
      "  img_size: 1296\n",
      "  in_chans: 3\n",
      "  mlp_ratio: 4\n",
      "  mlp_time_embed: false\n",
      "  name: uvit_t2i\n",
      "  num_clip_token: 77\n",
      "  num_heads: 10\n",
      "  patch_size: 4\n",
      "  qkv_bias: false\n",
      "optimizer:\n",
      "  betas: !!python/tuple\n",
      "  - 0.9\n",
      "  - 0.9\n",
      "  lr: 0.0002\n",
      "  name: adamw\n",
      "  weight_decay: 0.03\n",
      "sample:\n",
      "  cfg: false\n",
      "  mini_batch_size: 1\n",
      "  n_samples: 5\n",
      "  path: /Users/jihyeonje/unidiffuser/test/res/\n",
      "  sample_steps: 2\n",
      "  scale: 1.0\n",
      "sample_dir: /Users/jihyeonje/unidiffuser/test/\n",
      "seed: 1234\n",
      "train:\n",
      "  batch_size: 2\n",
      "  eval_interval: 5\n",
      "  log_interval: 10\n",
      "  n_steps: 50\n",
      "  save_interval: 5\n",
      "workdir: /Users/jihyeonje/unidiffuser/test/\n",
      "z_shape: !!python/tuple\n",
      "- 3\n",
      "- 1296\n",
      "- 4\n",
      "\n",
      "INFO:absl:Run on 1 devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare dataset...\n",
      "Prepare dataset ok\n",
      "attention mode is math\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:nnet has 1752151 parameters\n",
      "/var/folders/4h/2m4bntjn2wgdjw3zcvz8l96w0000gn/T/ipykernel_15803/496397642.py:21: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.snr = self.cum_alphas / self.cum_betas\n",
      "INFO:absl:use Schedule([0.         0.00085    0.0008547  0.00085941 0.00086413 0.00086887\n",
      " 0.00087362 0.00087839 0.00088316 0.00088795]..., 1000)\n",
      "INFO:absl:Start fitting, step=0, mixed_precision=no\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9243c5fc74b945ce833cdcf3be358418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/feats/train/5.npy\n",
      "test/feats/train/28.npy\n",
      "test/feats/train/11.npy\n",
      "test/feats/train/23.npy\n",
      "test/feats/train/2.npy\n",
      "test/feats/train/22.npy\n",
      "test/feats/train/15.npy\n",
      "test/feats/train/24.npy\n",
      "test/feats/train/27.npy\n",
      "test/feats/train/33.npy\n",
      "test/feats/train/9.npy\n",
      "test/feats/train/0.npy\n",
      "test/feats/train/8.npy\n",
      "test/feats/train/29.npy\n",
      "test/feats/train/10.npy\n",
      "test/feats/train/4.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Save and eval checkpoint 5...\n",
      "INFO:absl:eval_step: n_samples=5, sample_steps=5, algorithm=dpm_solver, mini_batch_size=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample2dir: 100%|██████████| 5/5 [00:03<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:absl:step=5 eval5=773.5457477517582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/feats/train/18.npy\n",
      "test/feats/train/17.npy\n",
      "test/feats/train/25.npy\n",
      "test/feats/train/26.npy\n",
      "test/feats/train/21.npy\n",
      "test/feats/train/3.npy\n",
      "test/feats/train/14.npy\n",
      "test/feats/train/32.npy\n",
      "test/feats/train/30.npy\n",
      "test/feats/train/6.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:{'step': '10', 'lr': '4e-07', 'loss': '2.09428'}\n",
      "INFO:absl:/Users/jihyeonje/unidiffuser/test/\n",
      "INFO:absl:Save and eval checkpoint 10...\n",
      "INFO:absl:eval_step: n_samples=5, sample_steps=5, algorithm=dpm_solver, mini_batch_size=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample2dir: 100%|██████████| 5/5 [00:02<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:absl:step=10 eval5=614.08916347545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/feats/train/12.npy\n",
      "test/feats/train/20.npy\n",
      "test/feats/train/13.npy\n",
      "test/feats/train/1.npy\n",
      "test/feats/train/34.npy\n",
      "test/feats/train/31.npy\n",
      "test/feats/train/16.npy\n",
      "test/feats/train/7.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Save and eval checkpoint 15...\n",
      "INFO:absl:eval_step: n_samples=5, sample_steps=5, algorithm=dpm_solver, mini_batch_size=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample2dir: 100%|██████████| 5/5 [00:02<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:absl:step=15 eval5=692.6620186652698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9f286494fa43ac87d620c29ddbaba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/feats/train/0.npy\n",
      "test/feats/train/7.npy\n",
      "test/feats/train/31.npy\n",
      "test/feats/train/29.npy\n",
      "test/feats/train/4.npy\n",
      "test/feats/train/21.npy\n",
      "test/feats/train/10.npy\n",
      "test/feats/train/17.npy\n",
      "test/feats/train/8.npy\n",
      "test/feats/train/5.npy\n",
      "test/feats/train/25.npy\n",
      "test/feats/train/11.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:{'step': '20', 'lr': '8e-07', 'loss': '2.05817'}\n",
      "INFO:absl:/Users/jihyeonje/unidiffuser/test/\n",
      "INFO:absl:Save and eval checkpoint 20...\n",
      "INFO:absl:eval_step: n_samples=5, sample_steps=5, algorithm=dpm_solver, mini_batch_size=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample2dir: 100%|██████████| 5/5 [00:03<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:absl:step=20 eval5=694.740091513724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/feats/train/16.npy\n",
      "test/feats/train/30.npy\n",
      "test/feats/train/28.npy\n",
      "test/feats/train/6.npy\n",
      "test/feats/train/2.npy\n",
      "test/feats/train/3.npy\n",
      "test/feats/train/27.npy\n",
      "test/feats/train/22.npy\n",
      "test/feats/train/26.npy\n",
      "test/feats/train/18.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Save and eval checkpoint 25...\n",
      "INFO:absl:eval_step: n_samples=5, sample_steps=5, algorithm=dpm_solver, mini_batch_size=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample2dir: 100%|██████████| 5/5 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1296, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:absl:step=25 eval5=774.7367134776658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/feats/train/9.npy\n",
      "test/feats/train/1.npy\n",
      "test/feats/train/13.npy\n",
      "test/feats/train/32.npy\n",
      "test/feats/train/24.npy\n",
      "test/feats/train/15.npy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jihyeonje/unidiffuser/exps.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(config)\n",
      "\u001b[1;32m/Users/jihyeonje/unidiffuser/exps.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m nnet\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m batch \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mto(device), \u001b[39mnext\u001b[39m(data_generator))\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m metrics \u001b[39m=\u001b[39m train_step(batch)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m nnet\u001b[39m.\u001b[39meval()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m \u001b[39mif\u001b[39;00m accelerator\u001b[39m.\u001b[39mis_main_process \u001b[39mand\u001b[39;00m train_state\u001b[39m.\u001b[39mstep \u001b[39m%\u001b[39m config\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mlog_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/Users/jihyeonje/unidiffuser/exps.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m loss \u001b[39m=\u001b[39m LSimple(_batch[\u001b[39m0\u001b[39m], _batch[\u001b[39m1\u001b[39m], nnet, _schedule)  \u001b[39m# currently only support the extracted feature version\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m _metrics[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m accelerator\u001b[39m.\u001b[39mgather(loss\u001b[39m.\u001b[39mdetach())\u001b[39m.\u001b[39mmean()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m accelerator\u001b[39m.\u001b[39;49mbackward(loss\u001b[39m.\u001b[39;49mmean())\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/exps.ipynb#X10sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m lr_scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unidiffuser/lib/python3.9/site-packages/accelerate/accelerator.py:884\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 884\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unidiffuser/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unidiffuser/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "gts = '/Users/jihyeonje/unidiffuser/test/res/*_gt.npy'\n",
    "preds = '/Users/jihyeonje/unidiffuser/test/res/*_pred.npy'\n",
    "idx = len(glob.glob(gts))\n",
    "loss = torch.nn.MSELoss()\n",
    "for id in range(idx):\n",
    "    target = torch.tensor(np.load(f'/Users/jihyeonje/unidiffuser/test/res/{id}_gt.npy'))\n",
    "    input = torch.tensor(np.load(f'/Users/jihyeonje/unidiffuser/test/res/{id}_pred.npy'))\n",
    "    ls = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = np.load(f'/Users/jihyeonje/unidiffuser/test/res/2_lig.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot = np.load(f'/Users/jihyeonje/unidiffuser/test/res/4_prot.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = lig[:,:3]\n",
    "one_hot = lig[:,3:]\n",
    "one_hot = np.argmax(one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import atom_encoder, atom_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chem_utils import get_bond_order, allowed_bonds, draw_mol, BasicMolecularMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 11, 14,  7,  5, 10,  6,  4, 14, 11,  1,  5,  3,  6,  6,  6,  3,\n",
       "       13,  4,  9,  1, 12,  6,  2,  9,  8,  5,  2,  4, 10, 12,  5,  5, 11,\n",
       "       13,  8, 14,  7, 15, 12, 15,  2,  1, 15,  8, 13,  8, 15,  7,  3, 15,\n",
       "        8,  4,  9,  7,  7,  3,  6,  8, 13,  8,  4,  8,  7,  7, 15,  3, 14,\n",
       "       10,  2, 14, 13, 10,  5, 10,  9,  6,  3,  9,  0,  1,  1, 11, 10, 11,\n",
       "       11,  7,  0,  9,  1,  0,  7,  9,  6,  8,  4,  7,  5,  6,  9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10,  5,  2,  4, 15,  8,  5,  1,  2, 10,  9,  0,  1,  7,  0, 13,\n",
       "        7, 11,  7,  7,  4,  9, 12,  3,  5,  0,  7,  2, 12, 10,  6,  5,  0,\n",
       "       11,  0,  2,  8, 11,  0,  9,  9,  6, 15,  1, 14,  2,  6,  4,  5,  9,\n",
       "        8,  3,  5,  7,  9,  8,  0,  2,  4, 13,  7,  4, 13,  9,  5,  6,  1,\n",
       "        8, 13,  3,  5,  3,  8, 11,  9, 11,  7, 11, 14,  2, 14, 11,  7, 11,\n",
       "        1,  0, 15,  9,  8,  7,  3,  4, 12, 12,  1,  6, 12, 10, 14])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "line": {
           "color": "black",
           "width": 0.5
          },
          "size": 10,
          "symbol": "circle"
         },
         "mode": "markers",
         "text": [
          6,
          11,
          14,
          7,
          5,
          10,
          6,
          4,
          14,
          11,
          1,
          5,
          3,
          6,
          6,
          6,
          3,
          13,
          4,
          9,
          1,
          12,
          6,
          2,
          9,
          8,
          5,
          2,
          4,
          10,
          12,
          5,
          5,
          11,
          13,
          8,
          14,
          7,
          15,
          12,
          15,
          2,
          1,
          15,
          8,
          13,
          8,
          15,
          7,
          3,
          15,
          8,
          4,
          9,
          7,
          7,
          3,
          6,
          8,
          13,
          8,
          4,
          8,
          7,
          7,
          15,
          3,
          14,
          10,
          2,
          14,
          13,
          10,
          5,
          10,
          9,
          6,
          3,
          9,
          0,
          1,
          1,
          11,
          10,
          11,
          11,
          7,
          0,
          9,
          1,
          0,
          7,
          9,
          6,
          8,
          4,
          7,
          5,
          6,
          9
         ],
         "type": "scatter3d",
         "x": [
          -15.630155563354492,
          -8.289185523986816,
          -19.46106719970703,
          -0.10679949074983597,
          5.008534908294678,
          -23.408340454101562,
          24.87263298034668,
          -2.1394221782684326,
          6.728390693664551,
          -2.5349485874176025,
          -8.030736923217773,
          -11.875762939453125,
          26.74740982055664,
          -4.9597554206848145,
          -14.896305084228516,
          12.172462463378906,
          25.231433868408203,
          -8.559188842773438,
          -10.002179145812988,
          0.30699974298477173,
          4.321926593780518,
          3.562549591064453,
          -22.53145980834961,
          19.853612899780273,
          -12.127571105957031,
          14.525443077087402,
          1.0459169149398804,
          0.44186827540397644,
          -3.4514880180358887,
          2.034675121307373,
          -13.18233585357666,
          -20.02290153503418,
          13.991105079650879,
          -2.411914587020874,
          1.0980697870254517,
          24.045166015625,
          -6.947576522827148,
          10.083136558532715,
          -9.513177871704102,
          3.4621384143829346,
          -10.234658241271973,
          14.558476448059082,
          -17.949504852294922,
          -15.81890869140625,
          3.5675010681152344,
          14.500341415405273,
          -26.923839569091797,
          -0.22152693569660187,
          15.696781158447266,
          5.5689473152160645,
          -2.221597671508789,
          -2.2559361457824707,
          2.947199821472168,
          0.842531681060791,
          6.012890338897705,
          19.676162719726562,
          18.557674407958984,
          24.267711639404297,
          -2.3880763053894043,
          10.555747985839844,
          15.213480949401855,
          31.640195846557617,
          10.194953918457031,
          -14.351860046386719,
          -10.792844772338867,
          -14.553653717041016,
          16.921144485473633,
          -39.61053466796875,
          1.5308195352554321,
          -26.078739166259766,
          5.490870952606201,
          -18.97201156616211,
          -17.264440536499023,
          -7.997450351715088,
          2.7817182540893555,
          -22.13304901123047,
          33.66252899169922,
          -0.8304166197776794,
          0.509669303894043,
          -23.594440460205078,
          -4.549003601074219,
          12.08925724029541,
          -32.31220626831055,
          22.116201400756836,
          -0.6718780398368835,
          1.7328342199325562,
          -10.39950180053711,
          -10.377327919006348,
          -11.222846984863281,
          -13.80714225769043,
          11.940592765808105,
          -5.92362642288208,
          29.76715087890625,
          -13.459979057312012,
          14.98902702331543,
          2.9965949058532715,
          -13.834359169006348,
          -22.528093338012695,
          4.988973140716553,
          2.6673288345336914
         ],
         "y": [
          24.590776443481445,
          13.607827186584473,
          -15.090645790100098,
          -18.590652465820312,
          4.827965259552002,
          -25.96601104736328,
          7.228093147277832,
          9.075156211853027,
          4.5456438064575195,
          -11.620437622070312,
          -1.9812419414520264,
          -30.424945831298828,
          21.767423629760742,
          -17.71037483215332,
          15.138471603393555,
          7.203776836395264,
          7.697854042053223,
          13.411072731018066,
          -4.455082416534424,
          3.8430423736572266,
          15.201351165771484,
          -0.8497500419616699,
          -11.57947826385498,
          -3.8794384002685547,
          13.026517868041992,
          10.049220085144043,
          4.1796650886535645,
          -24.910497665405273,
          -6.15598201751709,
          0.5145235657691956,
          -6.445050239562988,
          24.35936737060547,
          -13.947940826416016,
          6.207449913024902,
          11.562074661254883,
          -6.687444686889648,
          19.062353134155273,
          -9.623330116271973,
          -0.5426633358001709,
          -18.549110412597656,
          -18.43580436706543,
          9.466791152954102,
          -15.977340698242188,
          -9.887831687927246,
          -0.9430291056632996,
          -2.651456117630005,
          8.43414306640625,
          15.836886405944824,
          2.8208351135253906,
          -1.14271080493927,
          22.072603225708008,
          -17.021467208862305,
          -2.433953285217285,
          -18.244552612304688,
          -13.583368301391602,
          7.398838520050049,
          2.125732660293579,
          -1.9054092168807983,
          -20.11711883544922,
          -11.697600364685059,
          18.019859313964844,
          10.103259086608887,
          -7.710867404937744,
          -24.58608627319336,
          -7.323858261108398,
          -28.824298858642578,
          -6.954865455627441,
          19.29415512084961,
          -9.3823881149292,
          9.28288745880127,
          -6.399162769317627,
          12.574831008911133,
          -16.646007537841797,
          -1.0884873867034912,
          4.343401908874512,
          15.686840057373047,
          14.860660552978516,
          -1.128172755241394,
          13.705358505249023,
          -2.194967746734619,
          -20.836238861083984,
          7.993777751922607,
          22.929105758666992,
          -10.653026580810547,
          18.71433448791504,
          8.1563138961792,
          24.814186096191406,
          -14.163118362426758,
          -4.64146614074707,
          -12.76298999786377,
          -9.286300659179688,
          -18.56439208984375,
          8.818134307861328,
          1.1478135585784912,
          0.4995430111885071,
          -9.158174514770508,
          3.3157365322113037,
          11.248786926269531,
          -6.850546360015869,
          17.13054656982422
         ],
         "z": [
          12.873822212219238,
          12.461137771606445,
          9.772581100463867,
          9.766545295715332,
          22.842744827270508,
          -0.25634920597076416,
          17.76999282836914,
          -7.47058629989624,
          -11.187907218933105,
          10.975703239440918,
          -2.588552713394165,
          17.2541446685791,
          2.914638042449951,
          -1.0538214445114136,
          -25.367238998413086,
          3.142133951187134,
          -6.928555011749268,
          -16.617809295654297,
          -3.7361257076263428,
          3.306190252304077,
          18.274137496948242,
          -17.345508575439453,
          -21.61591339111328,
          17.465248107910156,
          7.712051868438721,
          -1.1909600496292114,
          4.193472862243652,
          -10.481175422668457,
          10.216723442077637,
          -5.864810943603516,
          -14.743252754211426,
          -35.29012680053711,
          4.215340614318848,
          -0.4129588305950165,
          10.522204399108887,
          2.335111141204834,
          -13.993556022644043,
          -15.886861801147461,
          13.7942533493042,
          2.078218460083008,
          5.151244163513184,
          -1.5806618928909302,
          -1.8518283367156982,
          5.198957920074463,
          -0.9177672863006592,
          -9.353404998779297,
          -39.68571472167969,
          9.19268798828125,
          4.706472873687744,
          -8.048306465148926,
          1.6416516304016113,
          33.97758483886719,
          -23.997047424316406,
          -2.6160616874694824,
          11.181846618652344,
          -28.737552642822266,
          0.47235190868377686,
          5.391366004943848,
          -19.979228973388672,
          11.599857330322266,
          -6.7994608879089355,
          13.896493911743164,
          -16.691238403320312,
          -18.074275970458984,
          19.152883529663086,
          6.623744487762451,
          -27.609209060668945,
          7.73328971862793,
          -6.760594367980957,
          -0.4090555012226105,
          -4.022244930267334,
          -10.097373008728027,
          18.76311492919922,
          -7.5771403312683105,
          -22.878318786621094,
          -21.92346954345703,
          4.502081394195557,
          4.067316055297852,
          -10.324603080749512,
          -20.05733871459961,
          -8.45348834991455,
          2.8757131099700928,
          -0.7747721076011658,
          12.9524507522583,
          -36.75400924682617,
          8.821763038635254,
          -10.55077075958252,
          23.887283325195312,
          -11.775461196899414,
          17.938493728637695,
          17.071495056152344,
          -2.596029043197632,
          3.937666416168213,
          10.692483901977539,
          4.165140151977539,
          -1.6528171300888062,
          2.448939800262451,
          8.456314086914062,
          3.7832515239715576,
          -1.335496425628662
         ]
        },
        {
         "hoverinfo": "none",
         "line": {
          "color": "grey",
          "width": 10
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          0.30699974298477173,
          1.0459169149398804,
          null,
          14.525443077087402,
          14.558476448059082,
          null
         ],
         "y": [
          3.8430423736572266,
          4.1796650886535645,
          null,
          10.049220085144043,
          9.466791152954102,
          null
         ],
         "z": [
          3.306190252304077,
          4.193472862243652,
          null,
          -1.1909600496292114,
          -1.5806618928909302,
          null
         ]
        },
        {
         "hoverinfo": "none",
         "line": {
          "color": "darkgrey",
          "width": 11
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [],
         "y": [],
         "z": []
        },
        {
         "hoverinfo": "none",
         "line": {
          "color": "black",
          "width": 12
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [],
         "y": [],
         "z": []
        }
       ],
       "layout": {
        "height": 625,
        "hovermode": "closest",
        "margin": {
         "t": 100
        },
        "scene": {
         "xaxis": {
          "showbackground": false,
          "showgrid": true,
          "showline": true,
          "showticklabels": false,
          "title": {
           "text": ""
          },
          "zeroline": false
         },
         "yaxis": {
          "showbackground": false,
          "showgrid": true,
          "showline": true,
          "showticklabels": false,
          "title": {
           "text": ""
          },
          "zeroline": false
         },
         "zaxis": {
          "showbackground": false,
          "showgrid": true,
          "showline": true,
          "showticklabels": false,
          "title": {
           "text": ""
          },
          "zeroline": false
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 650
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_mol(xyz, one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.01"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = BasicMolecularMetrics(atom_decoder)\n",
    "rdkit_metrics = metrics.evaluate([(xyz, one_hot)])\n",
    "val, unique = rdkit_metrics\n",
    "stable, n_bonds, ratio = check_stability(xyz, one_hot)\n",
    "lig_score = val + ratio\n",
    "lig_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234 #@param {type:\"number\"}\n",
    "steps = 50 #@param {type:\"slider\", min:0, max:100, step:1}\n",
    "cfg_scale = 8 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
    "n_samples = 2 #@param {type:\"number\"}\n",
    "nrow = 2 #@param {type:\"number\"}\n",
    "data_type = 1\n",
    "output_path = '/Users/jihyeonje/unidiffuser/test'\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "import torch\n",
    "import random\n",
    "import utils\n",
    "from dpm_solver_pp import NoiseScheduleVP, DPM_Solver\n",
    "from absl import logging\n",
    "import einops\n",
    "import libs.autoencoder\n",
    "import libs.clip\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torchvision.transforms as standard_transforms\n",
    "import numpy as np\n",
    "import clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.uvit_t2i import UViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UViT(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 100, kernel_size=(4, 4), stride=(4, 4))\n",
       "  )\n",
       "  (time_embed): Identity()\n",
       "  (context_embed): Linear(in_features=19, out_features=100, bias=True)\n",
       "  (text_embed): Linear(in_features=19, out_features=100, bias=True)\n",
       "  (text_out): Linear(in_features=100, out_features=19, bias=True)\n",
       "  (in_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): Block(\n",
       "    (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (out_blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=200, out_features=100, bias=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=200, out_features=100, bias=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=200, out_features=100, bias=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=200, out_features=100, bias=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=200, out_features=100, bias=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=100, out_features=300, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=100, out_features=400, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (skip_linear): Linear(in_features=200, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  (decoder_pred): Linear(in_features=100, out_features=48, bias=True)\n",
       "  (final_layer): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet = UViT(\n",
    "    img_size=1296,\n",
    "    in_chans=3,\n",
    "    patch_size=4,\n",
    "    embed_dim=100,\n",
    "    depth=12,\n",
    "    num_heads=10,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=False,\n",
    "    mlp_time_embed=False,\n",
    "    clip_dim=19,\n",
    "    num_clip_token=77\n",
    ")\n",
    "\n",
    "\n",
    "nnet.to(device)\n",
    "nnet.load_state_dict(torch.load('/Users/jihyeonje/unidiffuser/test/5.ckpt/nnet.pth', map_location='cpu'))\n",
    "nnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_betas = stable_diffusion_beta_schedule()\n",
    "N = len(_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schedule = Schedule(_betas)\n",
    "\n",
    "def cfg_nnet(x, timesteps, context):\n",
    "    _cond = nnet_ema(x, timesteps, context=context)\n",
    "    _empty_context = torch.tensor(dataset.empty_context, device=device)\n",
    "    _empty_context = einops.repeat(_empty_context, 'L D -> B L D', B=x.size(0))\n",
    "    _uncond = nnet_ema(x, timesteps, context=_empty_context)\n",
    "    return _cond + config.sample.scale * (_cond - _uncond)\n",
    "\n",
    "def joint_nnet(x, timesteps):\n",
    "    z, text = split_joint(x)\n",
    "    z_out, text_out = nnet(z, t_prot=timesteps, t_lig=timesteps, context = text)\n",
    "    if len(z_out.shape)==3:\n",
    "        z_out = torch.unsqueeze(z_out, 0)\n",
    "        text_out = torch.unsqueeze(text_out, 0)\n",
    "    x_out = combine_joint(z_out, text_out)\n",
    "\n",
    "    return x_out\n",
    "\n",
    "\n",
    "def train_step(_batch):\n",
    "    _metrics = dict()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = LSimple(_batch[0], _batch[1], nnet, _schedule)  # currently only support the extracted feature version\n",
    "    _metrics['loss'] = accelerator.gather(loss.detach()).mean()\n",
    "    accelerator.backward(loss.mean())\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    train_state.ema_update(config.get('ema_rate', 0.9999))\n",
    "    train_state.step += 1\n",
    "    return dict(lr=train_state.optimizer.param_groups[0]['lr'], **_metrics)\n",
    "\n",
    "\n",
    "def sample_fn(_n_samples, sample_steps):\n",
    "    _z_init = torch.randn(_n_samples, *config.z_shape, device=device)\n",
    "    _t_init = torch.randn(_n_samples, *(100,19), device=device)\n",
    "    _x_init = combine_joint(_z_init, _t_init)\n",
    "    noise_schedule = NoiseScheduleVP(schedule='discrete', betas=torch.tensor(_betas, device=device).float())\n",
    "\n",
    "    def model_fn(x, t_continuous):\n",
    "        t = t_continuous * _schedule.N\n",
    "        return joint_nnet(_x_init, t)\n",
    "\n",
    "    dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True, thresholding=False)\n",
    "    _z = dpm_solver.sample(_x_init, steps=sample_steps, eps=1. / _schedule.N, T=1.)\n",
    "    prot, lig = split_joint(_z)\n",
    "    return prot, lig\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_z, _text = sample_fn(_n_samples=5, sample_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 1296, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = _text[3][:,:3]\n",
    "one_hot = _text[3][:,3:]\n",
    "one_hot = np.argmax(one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 11,  7,  8,  1, 11,  7,  6,  4, 14, 14, 10,  1,  1, 11,  8, 11,  3,\n",
       "         9,  1,  6, 11,  8, 12,  1,  8,  4,  7,  9, 11,  9,  7,  5,  7, 13, 14,\n",
       "         8,  1,  7, 15, 15,  4, 12,  0,  1, 15,  8,  2, 11, 10, 14,  4,  8,  2,\n",
       "         0,  9,  2,  8, 13,  9,  4, 15,  7,  6,  2, 14, 15, 14, 15,  6,  2, 14,\n",
       "        14,  5,  6,  9,  2, 14,  7, 12, 10, 11,  8,  7,  3,  4, 13,  3, 12,  6,\n",
       "         5,  2, 15,  5,  5, 10,  9,  1,  2,  6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = _text[3][:,3:]\n",
    "np.argmax(one_hot, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unidiffuser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
