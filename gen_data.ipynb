{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem                                                                                                                                                                   \n",
    "from rdkit import RDLogger          \n",
    "from rdkit.Chem import AllChem\n",
    "from tqdm.auto import tqdm\n",
    "       \n",
    "import numpy as np                                                                                                                              \n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import protein\n",
    "import residue_constants\n",
    "from datasets import LigProtDatabase\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')                                                                                                                                                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.listdir(directory):\n",
    "        if dir !='.DS_Store':\n",
    "            foldr = os.path.join(directory, dir)\n",
    "        for i in os.listdir(foldr):\n",
    "            if i.endswith('.sdf'):\n",
    "                ligpaths.append(os.path.join(foldr, i))\n",
    "            elif i.endswith('protein.pdb'):\n",
    "                protpaths.append(os.path.join(foldr, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = open('/Users/jihyeonje/unidiffuser/cleanligs.pickle', 'rb')\n",
    "root = '/Users/jihyeonje/Downloads/PDBBind_processed'\n",
    "\n",
    "ligs = pickle.load(pth)\n",
    "\n",
    "cleanprots = []\n",
    "cleanligs = []\n",
    "for lig in ligs:\n",
    "    prot = lig.split('/')[-2]\n",
    "    foldr = root + '/' + prot\n",
    "    for dir in os.listdir(foldr):\n",
    "        if dir.endswith('.sdf'):\n",
    "            cleanligs.append(os.path.join(foldr, dir))\n",
    "        if dir.endswith('.pdb'):\n",
    "            cleanprots.append(os.path.join(foldr, dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein.read_pdb(cleanprots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.listdir(root + '/' + prot):\n",
    "    dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.listdir(root + '/' + prot):\n",
    "    if dir.endswith('protein.pdb'):\n",
    "        cleanprots.append(os.path.join(foldr, i))/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import LigProtDatabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jihyeonje/Downloads/PDBBind_processed/6ugp/6ugp_ligand.sdf'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanligs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_valid_dfs(protpaths, ligpaths):\n",
    "    max_id = len(protpaths)\n",
    "    image_ids = np.arange(0, max_id)\n",
    "    np.random.seed(42)\n",
    "    valid_ids = np.random.choice(\n",
    "        image_ids, size=int(0.2 * len(image_ids)), replace=False\n",
    "    )\n",
    "    train_ids = [id_ for id_ in image_ids if id_ not in valid_ids]\n",
    "    train_prot = list(map(protpaths.__getitem__, train_ids))\n",
    "    train_ligs = list(map(ligpaths.__getitem__, train_ids))\n",
    "    valid_prot = list(map(protpaths.__getitem__, valid_ids))\n",
    "    valid_ligs = list(map(ligpaths.__getitem__, valid_ids))\n",
    "    return train_prot, train_ligs, valid_prot, valid_ligs\n",
    "\n",
    "train_prot, train_lig, valid_prot, valid_lig = make_train_valid_dfs(cleanprots, cleanligs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = LigProtDatabase(protpaths = train_prot[0], ligpaths = train_lig[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jihyeonje/Downloads/PDBBind_processed/4hvb/4hvb_protein_processed.pdb'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jihyeonje/unidiffuser/gen_data.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jihyeonje/unidiffuser/gen_data.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a, b \u001b[39m=\u001b[39m datas\n",
      "File \u001b[0;32m~/unidiffuser/datasets.py:611\u001b[0m, in \u001b[0;36mLigProtDatabase.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m--> 611\u001b[0m     p_feats \u001b[39m=\u001b[39m load_feats_from_pdb(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprotpaths[index])\n\u001b[1;32m    612\u001b[0m     bb_coords \u001b[39m=\u001b[39m p_feats[\u001b[39m'\u001b[39m\u001b[39mbb_coords\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    613\u001b[0m     protein \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(bb_coords, \u001b[39m'\u001b[39m\u001b[39mh w c -> c h w\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/unidiffuser/datasets.py:547\u001b[0m, in \u001b[0;36mload_feats_from_pdb\u001b[0;34m(pdb, bb_atoms)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mLoad model input features from a PDB file or mmcif file.\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[39m- bb_atoms: list of backbone atom names to load\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39m- load_atom73: if True, also load atom73 features\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[39m- chain_residx_gap: residue index gap for chain breaks for PDBs with multiple chains\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    546\u001b[0m feats \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 547\u001b[0m protein_obj \u001b[39m=\u001b[39m protein\u001b[39m.\u001b[39;49mread_pdb(pdb)\n\u001b[1;32m    548\u001b[0m bb_idxs \u001b[39m=\u001b[39m [residue_constants\u001b[39m.\u001b[39matom_order[a] \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m bb_atoms]\n\u001b[1;32m    549\u001b[0m bb_coords \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(protein_obj\u001b[39m.\u001b[39matom_positions[:, bb_idxs])\n",
      "File \u001b[0;32m~/unidiffuser/protein.py:89\u001b[0m, in \u001b[0;36mread_pdb\u001b[0;34m(pdb_file, chain_id)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     parser \u001b[39m=\u001b[39m PDBParser(QUIET\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 89\u001b[0m structure \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49mget_structure(\u001b[39m\"\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m\"\u001b[39;49m, pdb_file)\n\u001b[1;32m     90\u001b[0m models \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(structure\u001b[39m.\u001b[39mget_models())\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(models) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unidiffuser/lib/python3.9/site-packages/Bio/PDB/PDBParser.py:96\u001b[0m, in \u001b[0;36mPDBParser.get_structure\u001b[0;34m(self, id, file)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m# Make a StructureBuilder instance (pass id of structure as parameter)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstructure_builder\u001b[39m.\u001b[39minit_structure(\u001b[39mid\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mwith\u001b[39;00m as_handle(file) \u001b[39mas\u001b[39;00m handle:\n\u001b[1;32m     97\u001b[0m     lines \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39mreadlines()\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m lines:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unidiffuser/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unidiffuser/lib/python3.9/site-packages/Bio/File.py:72\u001b[0m, in \u001b[0;36mas_handle\u001b[0;34m(handleish, mode, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Context manager to ensure we are using a handle.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[39mContext manager for arguments that can be passed to SeqIO and AlignIO read, write,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(handleish, mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m     73\u001b[0m         \u001b[39myield\u001b[39;00m fp\n\u001b[1;32m     74\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/'"
     ]
    }
   ],
   "source": [
    "a, b = datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in tqdm(enumerate(datas)):\n",
    "        if data is not None:\n",
    "            try:\n",
    "                prot, lig = data\n",
    "                \n",
    "                c_pad = torch.zeros(3, 1296 - prot.shape[1], 4)\n",
    "                prot = torch.cat([prot, c_pad], dim=1)\n",
    "            \n",
    "                pad_lig = torch.zeros(100, lig.shape[1])\n",
    "                pad_lig[:lig.shape[0], :] = lig\n",
    "                prot = prot.detach().cpu().numpy()\n",
    "                lig = pad_lig.detach().cpu().numpy()\n",
    "                np.save(os.path.join(save_dir, f'{idx}.npy'), (prot,lig))\n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = '/Users/jihyeonje/Downloads/PDBBind_processed/'\n",
    "ligpaths = []\n",
    "protpaths = []\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for dir in os.listdir(directory):\n",
    "    if dir !='.DS_Store':\n",
    "        foldr = os.path.join(directory, dir)\n",
    "    for i in os.listdir(foldr):\n",
    "        if i.endswith('.sdf'):\n",
    "            ligpaths.append(os.path.join(foldr, i))\n",
    "        elif i.endswith('.pdb'):\n",
    "            protpaths.append(os.path.join(foldr, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ligpaths = []\n",
    "clean_protpaths = []\n",
    "for i in range(len(ligpaths)):\n",
    "    suppl = Chem.SDMolSupplier(ligpaths[i])\n",
    "    if suppl is None: continue\n",
    "    try:\n",
    "        updated_mol= Chem.AddHs(suppl[0])\n",
    "        AllChem.EmbedMolecule(updated_mol)\n",
    "        clean_ligpaths.append(ligpaths[i])\n",
    "        clean_protpaths.append(protpaths[i])\n",
    "    except:\n",
    "        print('fail')\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_valid_dfs(protpaths, ligpaths):\n",
    "    max_id = len(protpaths)\n",
    "    image_ids = np.arange(0, max_id)\n",
    "    np.random.seed(42)\n",
    "    valid_ids = np.random.choice(\n",
    "        image_ids, size=int(0.2 * len(image_ids)), replace=False\n",
    "    )\n",
    "    train_ids = [id_ for id_ in image_ids if id_ not in valid_ids]\n",
    "    train_prot = list(map(protpaths.__getitem__, train_ids))\n",
    "    train_ligs = list(map(ligpaths.__getitem__, train_ids))\n",
    "    valid_prot = list(map(protpaths.__getitem__, valid_ids))\n",
    "    valid_ligs = list(map(ligpaths.__getitem__, valid_ids))\n",
    "    return train_prot, train_ligs, valid_prot, valid_ligs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prot, train_lig, valid_prot, valid_lig = make_train_valid_dfs(clean_protpaths, clean_ligpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = LigProtDatabase(protpaths = train_prot, ligpaths = train_lig)\n",
    "save_dir = f'/Users/jihyeonje/unidiffuser/test/feats/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in tqdm(enumerate(datas)):\n",
    "    if data is not None:\n",
    "        try:\n",
    "            prot, lig = data\n",
    "            \n",
    "            c_pad = torch.zeros(3, 1296 - prot.shape[1], 4)\n",
    "            prot = torch.cat([prot, c_pad], dim=1)\n",
    "        \n",
    "            pad_lig = torch.zeros(100, lig.shape[1])\n",
    "            pad_lig[:lig.shape[0], :] = lig\n",
    "            prot = prot.detach().cpu().numpy()\n",
    "            lig = pad_lig.detach().cpu().numpy()\n",
    "            np.save(os.path.join(save_dir, f'{idx}.npy'), (prot,lig))\n",
    "        except:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = LigProtDatabase(protpaths = valid_prot, ligpaths = valid_lig)\n",
    "save_dir = f'/Users/jihyeonje/unidiffuser/test/feats/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import libs.autoencoder\n",
    "import libs.clip\n",
    "from datasets import MSCOCODatabase\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def main():\n",
    "    c = torch.zeros((100,19))\n",
    "    save_dir = f'/Users/jihyeonje/unidiffuser/test/feats'\n",
    "    c = c.detach().cpu().numpy()\n",
    "    np.save(os.path.join(save_dir, f'empty_context.npy'), c)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unidiffuser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
